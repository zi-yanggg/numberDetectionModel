{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c45b0b",
   "metadata": {},
   "source": [
    "**CRNN Number Recognition**\n",
    "\n",
    "Import needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9e639",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6faa3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        self.samples = [line.strip().split(',') for line in lines]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(os.path.join(self.img_dir, img_path)).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor([int(c) for c in label], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceecb391",
   "metadata": {},
   "source": [
    "**CRNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, imgH, nc, nclass, nh):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(nc, 64, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.rnn = nn.LSTM(256, nh, bidirectional=True, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(nh*2, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.permute(0, 3, 1, 2)  # [batch, width, channels, height]\n",
    "        x = x.view(b, w, c*h)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6a7f4",
   "metadata": {},
   "source": [
    "**Hyperparameters & DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgH = 32\n",
    "nc = 1\n",
    "nclass = 11  # 0-9 digits + blank for CTC\n",
    "nh = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((imgH, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = NumberDataset('data/train', 'data/train_labels.txt', transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = NumberDataset('data/val', 'data/val_labels.txt', transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602a32b",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CRNN(imgH, nc, nclass, nh).to(device)\n",
    "criterion = nn.CTCLoss(blank=10)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def encode_labels(labels, max_len):\n",
    "    targets = []\n",
    "    lengths = []\n",
    "    for label in labels:\n",
    "        targets.extend(label.tolist())\n",
    "        lengths.append(len(label))\n",
    "    return torch.tensor(targets, dtype=torch.long), torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        targets, lengths = encode_labels(labels, labels.size(1))\n",
    "        targets = targets.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        output = model(images)  # [batch, width, nclass]\n",
    "        output = output.log_softmax(2)\n",
    "        input_lengths = torch.full(size=(output.size(0),), fill_value=output.size(1), dtype=torch.long)\n",
    "        loss = criterion(output.permute(1,0,2), targets, input_lengths, lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c3eebc",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de115e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "        output = output.softmax(2)\n",
    "        pred = output.argmax(2)\n",
    "        # Decode predictions as needed\n",
    "        print(\"Predicted:\", pred[0].cpu().numpy())\n",
    "        print(\"True:\", labels[0].cpu().numpy())\n",
    "        break  # Show one batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896c229",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'crnn_number_recognition.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
