{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c45b0b",
   "metadata": {},
   "source": [
    "**CRNN Number Recognition**\n",
    "\n",
    "Import needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install dependencies ---\n",
    "!pip install tensorflow matplotlib --quiet\n",
    "\n",
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d8c7b",
   "metadata": {},
   "source": [
    "Parameters and Character Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9983fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "img_height, img_width = 32, 100\n",
    "max_label_length = 5  # Max number length (e.g., up to 5 digits)\n",
    "characters = '0123456789-'  # Add '-' if you want to recognize negative numbers\n",
    "num_classes = len(characters) + 1  # +1 for CTC blank\n",
    "\n",
    "# --- Character mapping ---\n",
    "char_to_num = {c: i for i, c in enumerate(characters)}\n",
    "num_to_char = {i: c for i, c in enumerate(characters)}\n",
    "\n",
    "print(\"char_to_num:\", char_to_num)\n",
    "print(\"num_to_char:\", num_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9e639",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6faa3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Data ---\n",
    "def load_data(image_dir, label_csv):\n",
    "    df = pd.read_csv(label_csv)\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.imread(str(Path(image_dir) / row['filename']), cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = np.expand_dims(img, -1)\n",
    "        images.append(img)\n",
    "        labels.append(str(row['label']))\n",
    "    return np.array(images), labels\n",
    "\n",
    "X_train, y_train = load_data('/content/drive/MyDrive/NumberDetect/crnn_dataset/train/images', '/content/drive/MyDrive/NumberDetect/crnn_dataset/train/labels.csv')\n",
    "X_val, y_val = load_data('/content/drive/MyDrive/NumberDetect/crnn_dataset/val/images', '/content/drive/MyDrive/NumberDetect/crnn_dataset/val/labels.csv')\n",
    "\n",
    "# --- Encode Labels ---\n",
    "def encode_labels(labels, maxlen, char_to_num):\n",
    "    encoded = np.ones((len(labels), maxlen)) * -1\n",
    "    for i, label in enumerate(labels):\n",
    "        for j, char in enumerate(label):\n",
    "            encoded[i, j] = char_to_num[char]\n",
    "    return encoded\n",
    "\n",
    "y_train_encoded = encode_labels(y_train, max_label_length, char_to_num)\n",
    "y_val_encoded = encode_labels(y_val, max_label_length, char_to_num)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Original label: {y_train[i]}\")\n",
    "    print(f\"Encoded label: {y_train_encoded[i]}\")\n",
    "    # Decode back to string (ignoring -1)\n",
    "    decoded = ''.join([num_to_char[int(idx)] for idx in y_train_encoded[i] if idx != -1])\n",
    "    print(f\"Decoded back: {decoded}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceecb391",
   "metadata": {},
   "source": [
    "**CRNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CRNN Model ---\n",
    "def build_crnn(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    new_shape = (input_shape[1]//4, (input_shape[0]//4)*128)\n",
    "    x = layers.Reshape(target_shape=new_shape)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "crnn = build_crnn((img_height, img_width, 1), num_classes)\n",
    "crnn.summary()\n",
    "\n",
    "# --- CTC Loss Layer ---\n",
    "class CTCLossLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        y_pred, labels, input_length, label_length = inputs\n",
    "        loss = K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "        return y_pred\n",
    "\n",
    "# --- Model for Training ---\n",
    "labels = layers.Input(name='labels', shape=(max_label_length,), dtype='float32')\n",
    "input_length = layers.Input(name='input_length', shape=(1,), dtype='int64')\n",
    "label_length = layers.Input(name='label_length', shape=(1,), dtype='int64')\n",
    "y_pred = crnn.output\n",
    "ctc_out = CTCLossLayer()([y_pred, labels, input_length, label_length])\n",
    "training_model = models.Model([crnn.input, labels, input_length, label_length], ctc_out)\n",
    "training_model.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6a7f4",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def data_generator(X, y, batch_size=32):\n",
    "    while True:\n",
    "        idxs = np.random.permutation(len(X))\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            batch_idx = idxs[i:i+batch_size]\n",
    "            X_batch = X[batch_idx]\n",
    "            y_batch = y[batch_idx].astype(np.int32)\n",
    "            input_len = np.ones((len(X_batch), 1), dtype=np.int32) * (img_width // 4)\n",
    "            label_len = np.array([[len(label[label != -1])] for label in y_batch], dtype=np.int32)\n",
    "            yield (X_batch, y_batch, input_len, label_len), np.zeros(len(X_batch), dtype=np.float32)\n",
    "\n",
    "output_signature = (\n",
    "    (\n",
    "        tf.TensorSpec(shape=(None, img_height, img_width, 1), dtype=tf.float32),  # X_batch\n",
    "        tf.TensorSpec(shape=(None, max_label_length), dtype=tf.int32),          # y_batch\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.int32),                         # input_len\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.int32),                         # label_len\n",
    "    ),\n",
    "    tf.TensorSpec(shape=(None,), dtype=tf.float32)                                # dummy y\n",
    ")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(X_train, y_train_encoded, batch_size),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(X_val, y_val_encoded, batch_size),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "history = training_model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(X_train)//batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(X_val)//batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602a32b",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inference and Decoding ---\n",
    "def decode_prediction(pred, num_to_char):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    decoded, _ = K.ctc_decode(pred, input_length=input_len, greedy=True)\n",
    "    out = []\n",
    "    for seq in decoded[0].numpy():\n",
    "        text = ''.join([num_to_char.get(i, '') for i in seq if i != -1])\n",
    "        out.append(text)\n",
    "    return out\n",
    "\n",
    "# --- Test on Validation Set ---\n",
    "preds = crnn.predict(X_val[:10])\n",
    "decoded = decode_prediction(preds, num_to_char)\n",
    "for i in range(10):\n",
    "    plt.imshow(X_val[i].squeeze(), cmap='gray')\n",
    "    plt.title(f\"True: {y_val[i]} | Pred: {decoded[i]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896c229",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
